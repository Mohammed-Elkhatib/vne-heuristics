# Data Directory Documentation

This directory contains generated network data, algorithm results, and experimental datasets for the VNE Heuristics framework.

## Directory Structure

```
data/
├── input/                     # Generated networks and VNR batches
│   ├── networks/             # Substrate network files
│   │   ├── substrate_NAME_nodes.csv        # Node resources
│   │   └── substrate_NAME_links.csv        # Link resources
│   └── vnrs/                 # Virtual network request batches
│       ├── vnrs_NAME_metadata.csv          # VNR timing and metadata
│       ├── vnrs_NAME_nodes.csv             # VNR node requirements
│       └── vnrs_NAME_links.csv             # VNR link requirements
│
├── output/                   # Algorithm results and analysis
│   ├── results/             # Raw embedding results
│   │   └── results_ALGORITHM_TIMESTAMP.json
│   └── metrics/             # Performance metrics and analysis
│       └── metrics_ALGORITHM_TIMESTAMP.csv
│
└── data_documentation.md    # This file
```

## File Format Specifications

### Substrate Network Files

Substrate networks are stored as paired CSV files generated by `SubstrateNetwork.save_to_csv()`.

#### Substrate Nodes (`*_nodes.csv`)
```csv
node_id,cpu_capacity,memory_capacity,cpu_used,memory_used,x_coord,y_coord,node_type
0,150,200,0.0,0.0,25.5,75.2,default
1,100,150,0.0,0.0,45.1,30.8,default
2,75,100,0.0,0.0,80.3,60.1,default
```

**Columns**:
- `node_id`: Unique integer identifier for the substrate node
- `cpu_capacity`: Total CPU capacity (arbitrary units, always > 0)
- `memory_capacity`: Total memory capacity (arbitrary units, 0.0 if memory constraints disabled)
- `cpu_used`: Currently allocated CPU (managed by algorithms during embedding)
- `memory_used`: Currently allocated memory (managed by algorithms)
- `x_coord`, `y_coord`: Coordinates for visualization (random values 0.0-100.0)
- `node_type`: Node type classification (always "default" in current implementation)

#### Substrate Links (`*_links.csv`)
```csv
src_node,dst_node,bandwidth_capacity,bandwidth_used,delay,cost,reliability
0,1,1000,0.0,5.5,1.0,0.99
1,2,500,0.0,2.1,1.0,0.95
2,0,750,0.0,3.8,1.0,0.97
```

**Columns**:
- `src_node`, `dst_node`: Connected substrate node IDs (references to node_id)
- `bandwidth_capacity`: Total bandwidth capacity (arbitrary units, always > 0)
- `bandwidth_used`: Currently allocated bandwidth (managed by algorithms)
- `delay`: Link propagation delay (0.0 if delay constraints disabled, else 1.0-10.0)
- `cost`: Link usage cost (always 1.0 if cost constraints disabled)
- `reliability`: Link reliability (always 1.0 if reliability constraints disabled, else 0.9-1.0)

### Virtual Network Request Files

VNR batches are stored as triplet CSV files generated by `VNRBatch.save_to_csv()`.

#### VNR Metadata (`*_metadata.csv`)
```csv
vnr_id,arrival_time,holding_time,priority,node_count,link_count
0,0.0,1000.0,1,3,2
1,5.2,850.5,1,2,1
2,12.8,-1,1,4,3
```

**Columns**:
- `vnr_id`: Unique integer identifier for the VNR
- `arrival_time`: When the VNR arrives (simulation time units, ≥ 0.0)
- `holding_time`: How long the VNR remains active (-1 for infinite, else > 0.0)
- `priority`: VNR priority level (integer ≥ 1, higher = more important)
- `node_count`: Number of virtual nodes in this VNR
- `link_count`: Number of virtual links in this VNR

#### VNR Node Requirements (`*_nodes.csv`)
```csv
vnr_id,node_id,cpu_requirement,memory_requirement,constraints
0,0,25,50,"{}"
0,1,30,60,"{}"
0,2,20,40,"{}"
1,0,15,30,"{}"
1,1,25,50,"{}"
```

**Columns**:
- `vnr_id`: VNR identifier (foreign key to metadata)
- `node_id`: Virtual node identifier within the VNR (0, 1, 2, ...)
- `cpu_requirement`: Required CPU capacity (> 0, typically 10-50% of substrate capacity)
- `memory_requirement`: Required memory capacity (0.0 if memory constraints not used)
- `constraints`: JSON string with additional node constraints (currently always "{}")

#### VNR Link Requirements (`*_links.csv`)
```csv
vnr_id,src_node,dst_node,bandwidth_requirement,delay_constraint,reliability_requirement,constraints
0,0,1,100,10.0,0.95,"{}"
0,1,2,75,0.0,0.0,"{}"
1,0,1,120,0.0,0.0,"{}"
```

**Columns**:
- `vnr_id`: VNR identifier (foreign key to metadata)
- `src_node`, `dst_node`: Connected virtual node IDs within the VNR
- `bandwidth_requirement`: Required bandwidth capacity (> 0)
- `delay_constraint`: Maximum acceptable delay (0.0 if no constraint)
- `reliability_requirement`: Minimum required reliability (0.0 if no requirement)
- `constraints`: JSON string with additional link constraints (currently always "{}")

### Algorithm Results (`results_*.json`)

Algorithm results are saved by `RunCommand._save_results()` in JSON format:

```json
{
  "metadata": {
    "timestamp": "2025-01-28T15:30:45.123456",
    "result_count": 3
  },
  "results": [
    {
      "vnr_id": "0",
      "success": true,
      "node_mapping": {
        "0": "3",
        "1": "7",
        "2": "1"
      },
      "link_mapping": {
        "0-1": ["3", "2", "7"],
        "1-2": ["7", "1"]
      },
      "revenue": 250.75,
      "cost": 145.50,
      "execution_time": 0.0023,
      "failure_reason": null,
      "timestamp": 1748379950.123,
      "algorithm_name": "Yu et al. (2008) Two-Stage Algorithm",
      "metadata": {
        "allocated_nodes": 3,
        "allocated_links": 2,
        "algorithm_stages": 2
      }
    },
    {
      "vnr_id": "1", 
      "success": false,
      "node_mapping": {},
      "link_mapping": {},
      "revenue": 0.0,
      "cost": 0.0,
      "execution_time": 0.0015,
      "failure_reason": "Node mapping failed - insufficient CPU resources",
      "timestamp": 1748379950.125,
      "algorithm_name": "Yu et al. (2008) Two-Stage Algorithm",
      "metadata": {}
    }
  ]
}
```

**Fields**:
- `vnr_id`: Identifier of the processed VNR (string)
- `success`: Whether embedding was successful (boolean)
- `node_mapping`: Map of virtual node IDs to substrate node IDs (strings)
- `link_mapping`: Map of virtual links to substrate paths (string keys like "0-1")
- `revenue`: Revenue from successful embedding (calculated using standard VNE formula)
- `cost`: Cost of embedding attempt (calculated using standard VNE formula)
- `execution_time`: Algorithm execution time in seconds (float)
- `failure_reason`: Reason for failure if unsuccessful (string or null)
- `timestamp`: Unix timestamp of embedding attempt (float)
- `algorithm_name`: Name of algorithm used (string)
- `metadata`: Algorithm-specific additional information (object)

### Performance Metrics (`metrics_*.csv`)

Metrics are calculated by `MetricsCommand` and saved in CSV format:

```csv
metric_category,metric_name,value,description
basic_stats,total_requests,100,Basic statistic: total_requests
basic_stats,successful_requests,85,Basic statistic: successful_requests
basic_stats,failed_requests,15,Basic statistic: failed_requests
primary_metrics,acceptance_ratio,0.85,Primary VNE metric: acceptance_ratio
primary_metrics,blocking_probability,0.15,Primary VNE metric: blocking_probability
primary_metrics,total_revenue,1250.75,Primary VNE metric: total_revenue
primary_metrics,total_cost,450.25,Primary VNE metric: total_cost
primary_metrics,revenue_to_cost_ratio,2.78,Primary VNE metric: revenue_to_cost_ratio
performance_metrics,average_execution_time,0.0045,Performance metric: average_execution_time
performance_metrics,throughput,8.5,Performance metric: throughput
utilization_metrics,avg_node_cpu_util,0.67,Resource utilization: avg_node_cpu_util
utilization_metrics,avg_node_memory_util,0.72,Resource utilization: avg_node_memory_util
utilization_metrics,avg_link_bandwidth_util,0.43,Resource utilization: avg_link_bandwidth_util
```

## Data Generation Commands

### Generate Substrate Networks

```bash
# Basic substrate network (creates substrate_20_nodes.csv and substrate_20_links.csv)
python main.py generate substrate --nodes 20 --save data/substrate_20

# Erdős-Rényi random graph
python main.py generate substrate --nodes 50 --topology erdos_renyi --edge-prob 0.15 --save data/erdos_50

# Barabási-Albert scale-free network  
python main.py generate substrate --nodes 100 --topology barabasi_albert --attachment-count 3 --save data/barabasi_100

# Grid topology
python main.py generate substrate --nodes 36 --topology grid --save data/grid_36

# Custom resource ranges
python main.py generate substrate --nodes 30 \
  --cpu-range 50 200 --memory-range 100 300 --bandwidth-range 500 2000 \
  --save data/high_capacity_30

# With random seed for reproducibility
python main.py generate substrate --nodes 25 --seed 42 --save data/reproducible_25
```

### Generate VNR Batches

```bash
# Basic VNR batch (creates vnrs_50_metadata.csv, vnrs_50_nodes.csv, vnrs_50_links.csv)
python main.py generate vnrs --count 50 --substrate data/substrate_20 --save data/vnrs_50

# Different topologies
python main.py generate vnrs --count 30 --substrate data/substrate_20 \
  --topology star --nodes-range 3 8 --save data/star_vnrs

python main.py generate vnrs --count 40 --substrate data/substrate_20 \
  --topology linear --nodes-range 2 6 --save data/linear_vnrs

python main.py generate vnrs --count 35 --substrate data/substrate_20 \
  --topology tree --nodes-range 4 10 --save data/tree_vnrs

# Custom resource ratios
python main.py generate vnrs --count 100 --substrate data/substrate_50 \
  --cpu-ratio 0.3 0.7 --memory-ratio 0.4 0.8 --bandwidth-ratio 0.2 0.6 \
  --save data/high_demand_vnrs

# Custom arrival patterns
python main.py generate vnrs --count 75 --substrate data/substrate_30 \
  --arrival-rate 15.0 --lifetime-mean 500.0 --save data/dense_arrival_vnrs

# With random seed for reproducibility
python main.py generate vnrs --count 60 --substrate data/substrate_25 \
  --seed 123 --save data/reproducible_vnrs
```

## Data Analysis Examples

### Load and Analyze Results

```python
import json
import pandas as pd
import matplotlib.pyplot as plt

# Load embedding results
with open('data/output/results/results_yu2008_20250128_153045.json', 'r') as f:
    data = json.load(f)

results = data['results']
df = pd.DataFrame(results)

# Basic statistics
print(f"Acceptance ratio: {df['success'].mean():.2%}")
print(f"Average revenue: {df[df['success']]['revenue'].mean():.2f}")
print(f"Average execution time: {df['execution_time'].mean():.4f}s")

# Plot revenue distribution
successful_results = df[df['success']]
plt.hist(successful_results['revenue'], bins=20)
plt.xlabel('Revenue')
plt.ylabel('Frequency')
plt.title('Revenue Distribution for Successful Embeddings')
plt.show()

# Analyze failure reasons
failed_results = df[~df['success']]
failure_counts = failed_results['failure_reason'].value_counts()
print("\nFailure reasons:")
for reason, count in failure_counts.items():
    print(f"  {reason}: {count}")
```

### Network Statistics

```python
import pandas as pd

# Load substrate network
nodes_df = pd.read_csv('data/substrate_50_nodes.csv')
links_df = pd.read_csv('data/substrate_50_links.csv')

# Network statistics
print(f"Network size: {len(nodes_df)} nodes, {len(links_df)} links")
print(f"Average degree: {2 * len(links_df) / len(nodes_df):.2f}")
print(f"Total CPU capacity: {nodes_df['cpu_capacity'].sum()}")
print(f"Total memory capacity: {nodes_df['memory_capacity'].sum()}")
print(f"Total bandwidth capacity: {links_df['bandwidth_capacity'].sum()}")

# Resource utilization after experiment
print(f"CPU utilization: {nodes_df['cpu_used'].sum() / nodes_df['cpu_capacity'].sum():.2%}")
print(f"Bandwidth utilization: {links_df['bandwidth_used'].sum() / links_df['bandwidth_capacity'].sum():.2%}")
```

### VNR Batch Analysis

```python
import pandas as pd

# Load VNR batch
metadata_df = pd.read_csv('data/vnrs_100_metadata.csv')
nodes_df = pd.read_csv('data/vnrs_100_nodes.csv')
links_df = pd.read_csv('data/vnrs_100_links.csv')

# VNR statistics
print(f"VNR batch size: {len(metadata_df)}")
print(f"Average VNR size: {metadata_df['node_count'].mean():.1f} nodes")
print(f"Average connectivity: {metadata_df['link_count'].mean():.1f} links")
print(f"Total CPU demand: {nodes_df['cpu_requirement'].sum()}")
print(f"Total bandwidth demand: {links_df['bandwidth_requirement'].sum()}")

# Temporal analysis
print(f"Arrival time range: {metadata_df['arrival_time'].min():.1f} to {metadata_df['arrival_time'].max():.1f}")
finite_holding = metadata_df[metadata_df['holding_time'] != -1]
if len(finite_holding) > 0:
    print(f"Average holding time: {finite_holding['holding_time'].mean():.1f}")
```

## Common Data Scenarios

### Small Test Networks
```bash
# Quick testing with small networks
python main.py generate substrate --nodes 5 --save data/test_small
python main.py generate vnrs --count 3 --substrate data/test_small --save data/test_vnrs
python main.py run --algorithm yu2008 --substrate data/test_small --vnrs data/test_vnrs
```

### Realistic Evaluation Networks  
```bash
# Medium-scale realistic networks
python main.py generate substrate --nodes 50 --topology barabasi_albert --save data/realistic_50
python main.py generate vnrs --count 200 --substrate data/realistic_50 \
  --cpu-ratio 0.1 0.4 --memory-ratio 0.1 0.4 --save data/realistic_vnrs
```

### Stress Testing Networks
```bash
# High-load scenario
python main.py generate substrate --nodes 30 --cpu-range 20 60 --memory-range 30 80 --save data/constrained
python main.py generate vnrs --count 100 --substrate data/constrained \
  --cpu-ratio 0.4 0.8 --memory-ratio 0.4 0.8 --save data/demanding_vnrs
```

### Comparative Studies
```bash
# Generate multiple substrate topologies for comparison
python main.py generate substrate --nodes 40 --topology erdos_renyi --save data/compare_erdos
python main.py generate substrate --nodes 40 --topology barabasi_albert --save data/compare_barabasi

# Same VNR batch for both (using same seed)
python main.py generate vnrs --count 100 --substrate data/compare_erdos --seed 123 --save data/compare_vnrs_erdos
python main.py generate vnrs --count 100 --substrate data/compare_barabasi --seed 123 --save data/compare_vnrs_barabasi
```

## Data Quality Guidelines

### Substrate Networks
- **Connectivity**: Generated networks are always connected (verified during generation)
- **Resource Balance**: CPU and bandwidth capacities are balanced by generator
- **Topology Realism**: Use appropriate topologies for research scenario
- **Scale Appropriateness**: Match network size to computational resources

### VNR Batches
- **Feasibility**: Generator ensures reasonable resource ratios
- **Diversity**: Automatic variation in VNR sizes and requirements
- **Arrival Patterns**: Poisson arrivals by default, configurable distributions
- **Lifetime Variation**: Exponential holding times with configurable mean

### Result Validation
- **Consistency Checks**: BaseAlgorithm validates all embeddings
- **Mapping Validity**: Intra-VNR separation enforced automatically
- **Revenue/Cost Sanity**: Standard VNE formulas ensure realistic values

## Storage Recommendations

### File Organization
```
data/
├── experiments/
│   ├── experiment_1/
│   │   ├── substrate_50_erdos_nodes.csv
│   │   ├── substrate_50_erdos_links.csv
│   │   ├── vnrs_100_erdos_metadata.csv
│   │   ├── vnrs_100_erdos_nodes.csv
│   │   ├── vnrs_100_erdos_links.csv
│   │   └── results/
│   └── experiment_2/
│       └── ...
├── benchmarks/
│   ├── standard_substrate_100_nodes.csv
│   ├── standard_substrate_100_links.csv
│   └── standard_vnrs_500_*
└── archive/
    └── old_experiments/
```

### Backup Strategy
- **Version Control**: Use git for code, .gitignore for large data files
- **Compression**: Use `gzip` for large result files
- **Documentation**: Keep detailed records of experimental parameters
- **Replication**: Store generation commands and seeds for reproducibility

## Troubleshooting

### Common Issues

**File Not Found Errors**:
```bash
# Check file naming convention (files are created in pairs/triplets)
ls data/substrate_20*
# Expected: substrate_20_nodes.csv, substrate_20_links.csv

ls data/vnrs_50*
# Expected: vnrs_50_metadata.csv, vnrs_50_nodes.csv, vnrs_50_links.csv
```

**Empty Results**:
- Check VNR feasibility: high resource requirements may cause all rejections
- Verify substrate network connectivity: isolated nodes cause failures
- Use `--debug` flag to see detailed embedding attempts

**Memory Issues with Large Networks**:
- Monitor RAM usage during generation and execution
- Use smaller batch sizes for VNR processing
- Consider network size limits based on available resources

**Inconsistent Results**:
- Set random seeds for reproducibility: `--seed 42`
- Ensure consistent configuration across runs
- Verify that substrate network hasn't been modified between runs

## Performance Notes

### File Size Estimates
- **Small networks** (10-20 nodes): ~1-5 KB per file
- **Medium networks** (50-100 nodes): ~10-50 KB per file  
- **Large networks** (200+ nodes): ~100+ KB per file
- **Result files**: ~1-10 MB for 100-1000 VNRs (JSON format)
- **Metrics files**: ~10-100 KB per experiment (CSV format)

### Generation Time
- **Substrate networks**: Nearly instantaneous for <1000 nodes
- **VNR batches**: Seconds for <1000 VNRs
- **Algorithm execution**: Varies by algorithm complexity and network size

### I/O Considerations
- **CSV parsing**: pandas recommended for analysis
- **JSON loading**: Standard library json module handles all result files
- **UTF-8 encoding**: All files use UTF-8 encoding consistently
- **Cross-platform**: Path handling works on Windows, macOS, and Linux

This data directory serves as the foundation for all VNE experiments and analysis. Proper data management ensures reproducible research and meaningful comparisons between algorithms.